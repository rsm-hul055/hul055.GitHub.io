[
  {
    "objectID": "blog/first-blog/index.html",
    "href": "blog/first-blog/index.html",
    "title": "first-blog",
    "section": "",
    "text": "This is my first blog post. I’m excited to share my work with the world!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "blog/blog.html",
    "href": "blog/blog.html",
    "title": "Blog",
    "section": "",
    "text": "first-blog\n\n\n\n\n\n\n\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hui’s Website",
    "section": "",
    "text": "Here is a paragraph about me! I am a graduate student in UCSD Rady school\nlast updated 2025-04-06"
  },
  {
    "objectID": "Resume/resume.html",
    "href": "Resume/resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "resume/resume.html",
    "href": "resume/resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Homework",
    "section": "",
    "text": "Homework 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "About\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResume\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHui’s Website\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Homework\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfirst-blog\n\n\n\n\n\n\n\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project/projects.html",
    "href": "project/projects.html",
    "title": "My Homework",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nHui Liu\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project/hw1/index.html",
    "href": "project/hw1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe core hypothesis explored in the experiment is whether offering matching donations increases the likelihood and size of charitable contributions. Matching donations are often used by nonprofits under the belief that people are more likely to give when they know their donation will be “matched” by another funder.\nTo test this idea, Karlan and List conducted a large-scale natural field experiment involving 50,083 individuals who had previously donated to a politically conservative nonprofit organization. These individuals were randomly assigned to receive fundraising letters with different conditions: - Control group: received a standard donation request. - Treatment group: received one of three types of matching grants — a 1:1, 2:1, or 3:1 match. - Each letter also varied the match threshold (i.e., how much the funder was willing to match in total) and the suggested donation amount (either equal to or a multiplier of the donor’s previous contribution).\nThe strength of this design lies in its scale, natural setting (real donors, real money), and random assignment, which allows for clean causal inference.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "project/hw1/index.html#introduction",
    "href": "project/hw1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe core hypothesis explored in the experiment is whether offering matching donations increases the likelihood and size of charitable contributions. Matching donations are often used by nonprofits under the belief that people are more likely to give when they know their donation will be “matched” by another funder.\nTo test this idea, Karlan and List conducted a large-scale natural field experiment involving 50,083 individuals who had previously donated to a politically conservative nonprofit organization. These individuals were randomly assigned to receive fundraising letters with different conditions: - Control group: received a standard donation request. - Treatment group: received one of three types of matching grants — a 1:1, 2:1, or 3:1 match. - Each letter also varied the match threshold (i.e., how much the funder was willing to match in total) and the suggested donation amount (either equal to or a multiplier of the donor’s previous contribution).\nThe strength of this design lies in its scale, natural setting (real donors, real money), and random assignment, which allows for clean causal inference.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "project/hw1/index.html#data",
    "href": "project/hw1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nWe analyze the dataset provided by the authors, which contains 50,083 observations — each representing a recipient of a fundraising letter. The dataset includes variables describing:\n\nExperimental assignment: whether the individual received a control or treatment letter, and what kind of match ratio they received\nPast donation behavior: frequency, amount, time since last donation, etc.\nDemographics and political geography (e.g., red/blue state or county)\nThe outcome variables: whether the individual donated and how much they gave\n\nBelow is the code used to load the dataset into Python and show a snapshot of its structure:\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Display shape and variable names\ndf.shape, df.columns.tolist()\n\n((50083, 51),\n ['treatment',\n  'control',\n  'ratio',\n  'ratio2',\n  'ratio3',\n  'size',\n  'size25',\n  'size50',\n  'size100',\n  'sizeno',\n  'ask',\n  'askd1',\n  'askd2',\n  'askd3',\n  'ask1',\n  'ask2',\n  'ask3',\n  'amount',\n  'gave',\n  'amountchange',\n  'hpa',\n  'ltmedmra',\n  'freq',\n  'years',\n  'year5',\n  'mrm2',\n  'dormant',\n  'female',\n  'couple',\n  'state50one',\n  'nonlit',\n  'cases',\n  'statecnt',\n  'stateresponse',\n  'stateresponset',\n  'stateresponsec',\n  'stateresponsetminc',\n  'perbush',\n  'close25',\n  'red0',\n  'blue0',\n  'redcty',\n  'bluecty',\n  'pwhite',\n  'pblack',\n  'page18_39',\n  'ave_hh_sz',\n  'median_hhincome',\n  'powner',\n  'psch_atlstba',\n  'pop_propurban'])\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another."
  },
  {
    "objectID": "project/hw1/index.html#balance-check",
    "href": "project/hw1/index.html#balance-check",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Balance Check",
    "text": "Balance Check\nWe begin by checking whether the treatment and control groups are balanced in terms of observable characteristics. This is a common first step in analyzing randomized experiments: if randomization was implemented correctly, both groups should be similar on all baseline variables.\nHere, we focus on one such variable: the number of months since a donor’s last contribution (mrm2).\nThe average for the control group is 12.99 months, while for the treatment group it is 13.01 months. A t-test comparing these means yields t = 0.12, p = 0.905, indicating no statistically significant difference.\nWe also estimate a linear regression of mrm2 on the treatment indicator. The coefficient is effectively zero and not statistically significant, confirming the same conclusion.\nThese results suggest that the randomization was successful: the two groups appear well-balanced with respect to prior giving behavior. This gives us confidence that subsequent differences in donation outcomes can be attributed to the experimental treatments.\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n#  treatment + control + mrm2\ndf_subset = df[[\"treatment\", \"control\", \"mrm2\"]].dropna()\n\n# \nmeans = df_subset.groupby(\"treatment\")[\"mrm2\"].mean()\n\n# t-test \nt_stat, p_value = stats.ttest_ind(\n    df_subset[df_subset[\"treatment\"] == 1][\"mrm2\"],\n    df_subset[df_subset[\"treatment\"] == 0][\"mrm2\"],\n    equal_var=False  # Welch's t-test\n)\n\n\nX = sm.add_constant(df_subset[\"treatment\"])\nmodel = sm.OLS(df_subset[\"mrm2\"], X).fit()\n\n\nprint(\"=== mean value ===\")\nprint(means)\nprint(\"\\n=== t-test ===\")\nprint(f\"t = {t_stat:.3f}, p = {p_value:.3f}\")\nprint(\"\\n=== OLS Regression result ===\")\nprint(model.summary())\n\n=== mean value ===\ntreatment\n0    12.998142\n1    13.011828\nName: mrm2, dtype: float64\n\n=== t-test ===\nt = 0.120, p = 0.905\n\n=== OLS Regression result ===\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        22:46:31   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\n\n\n\nWhy check for balance?\n\n\n\nBalance tests help confirm that the randomization worked as expected. If the treatment and control groups are similar on baseline characteristics, we can be more confident that later differences in donation outcomes are due to the treatment and not underlying differences between groups."
  },
  {
    "objectID": "project/hw1/index.html#experimental-results",
    "href": "project/hw1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation."
  },
  {
    "objectID": "project/hw1/index.html#simulation-experiment",
    "href": "project/hw1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThis chart illustrates the Law of Large Numbers using a simulated experiment. I generated 10,000 simulated donation outcomes for the control group (Bernoulli p = 0.018) and 10,000 for the treatment group (Bernoulli p = 0.022), and then computed the cumulative average of their differences.\nAs shown, the cumulative average is quite noisy at the beginning due to the small sample size — early differences fluctuate dramatically. However, as the number of observations increases, the cumulative average stabilizes around 0.004 (the true treatment effect), demonstrating convergence.\nThis supports the intuition behind large sample inference: as the sample size grows, random variation diminishes, and estimates converge to their true values.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set probabilities\np_control = 0.018\np_treatment = 0.022\nn = 10_000\n\n# Simulate donation outcomes\nnp.random.seed(42)\ncontrol = np.random.binomial(n=1, p=p_control, size=n)\ntreatment = np.random.binomial(n=1, p=p_treatment, size=n)\n\n# Calculate difference vector and cumulative average\ndiff = treatment - control\ncumulative_avg = np.cumsum(diff) / np.arange(1, n + 1)\n\n# Plot cumulative average\nfig, ax = plt.subplots()\nax.plot(cumulative_avg, label=\"Cumulative Average\")\nax.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True Treatment Effect (0.004)\")\nax.set_title(\"Law of Large Numbers: Cumulative Average of Differences\")\nax.set_xlabel(\"Sample Size\")\nax.set_ylabel(\"Cumulative Average\")\nax.legend()\nfig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set random seed\nnp.random.seed(123)\n\n# Simulation parameters\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\n\n# Create 4 histograms\nfig, axs = plt.subplots(2, 2, figsize=(8, 4))\n\nfor i, n in enumerate(sample_sizes):\n    differences = []\n    for _ in range(1000):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = treatment.mean() - control.mean()\n        differences.append(diff)\n\n    ax = axs[i // 2, i % 2]\n    ax.hist(differences, bins=30, color=\"grey\", edgecolor=\"black\")\n    ax.set_title(f\"Sample Size: {n}\")\n    ax.set_xlabel(\"Average Difference\")\n    ax.set_ylabel(\"Frequency\")\n\nplt.tight_layout()\nfig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs shown above, these histograms display the distribution of average differences across 1000 simulations for various sample sizes. When the sample size is small (e.g., 50), the distribution is highly variable and not symmetric. As the sample size increases, the distributions become increasingly symmetric and bell-shaped, illustrating the Central Limit Theorem: the sampling distribution of the sample mean approaches a normal distribution as the sample size increases."
  },
  {
    "objectID": "project/hw1/hw1.html",
    "href": "project/hw1/hw1.html",
    "title": "HuiL's Website",
    "section": "",
    "text": "import pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n#  treatment + control + mrm2\ndf_subset = df[[\"treatment\", \"control\", \"mrm2\"]].dropna()\n\n# \nmeans = df_subset.groupby(\"treatment\")[\"mrm2\"].mean()\n\n# t-test \nt_stat, p_value = stats.ttest_ind(\n    df_subset[df_subset[\"treatment\"] == 1][\"mrm2\"],\n    df_subset[df_subset[\"treatment\"] == 0][\"mrm2\"],\n    equal_var=False  # Welch's t-test\n)\n\n\nX = sm.add_constant(df_subset[\"treatment\"])\nmodel = sm.OLS(df_subset[\"mrm2\"], X).fit()\n\n\nprint(\"=== mean value ===\")\nprint(means)\nprint(\"\\n=== t-test ===\")\nprint(f\"t = {t_stat:.3f}, p = {p_value:.3f}\")\nprint(\"\\n=== OLS Regression result ===\")\nprint(model.summary())\n\n=== mean value ===\ntreatment\n0    12.998142\n1    13.011828\nName: mrm2, dtype: float64\n\n=== t-test ===\nt = 0.120, p = 0.905\n\n=== OLS Regression result ===\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        21:28:17   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\nimport statsmodels.formula.api as smf\n\n# 创建 treatment vs control 捐款比例 barplot 所需数据\ngave_by_group = df.groupby(\"treatment\")[\"gave\"].mean().rename({0: \"Control\", 1: \"Treatment\"})\n\n# t-test 检验：是否捐款 (gave) 在 treatment vs control 中有显著差异\nt_stat, p_value = stats.ttest_ind(\n    df[df[\"treatment\"] == 1][\"gave\"],\n    df[df[\"treatment\"] == 0][\"gave\"],\n    equal_var=False\n)\n\n# 线性回归：gave ~ treatment\nols_model = smf.ols(\"gave ~ treatment\", data=df).fit()\n\n# Probit 回归\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit(disp=False)\n\n# 绘图\nfig, ax = plt.subplots(figsize=(6,4))\ngave_by_group.plot(kind='bar', color=[\"pink\", \"blue\"], ax=ax)\nax.set_ylabel(\"Proportion Donated\")\nax.set_title(\"Donation Rate by Treatment Group\")\nax.set_xticklabels([\"Control\", \"Treatment\"], rotation=0)\nax.set_ylim(0, 0.05)\nplt.tight_layout()\n\n\nprint(\"t =\", t_stat, \"p =\", p_value)\n\nprint(ols_model.summary2().tables[1])\n\nprint(probit_model.summary2().tables[1])\n\nt = 3.2094621908279835 p = 0.001330982345091417\n              Coef.  Std.Err.          t         P&gt;|t|    [0.025    0.975]\nIntercept  0.017858  0.001101  16.224643  4.779032e-59  0.015701  0.020016\ntreatment  0.004180  0.001348   3.101361  1.927403e-03  0.001538  0.006822\n              Coef.  Std.Err.         z     P&gt;|z|    [0.025    0.975]\nIntercept -2.100141  0.023316 -90.07277  0.000000 -2.145840 -2.054443\ntreatment  0.086785  0.027879   3.11293  0.001852  0.032143  0.141426\n\n\n\n\n\n\n\n\n\n\n# 先构建子集，只保留 matched treatment 组（treatment==1）下的不同 ratio\ndf_matched = df[(df[\"treatment\"] == 1)]\n\n# 计算每组捐赠率\nrates = df_matched.groupby(\"ratio\")[\"gave\"].mean()\nprint(\"Donation rates by match ratio:\")\nprint(rates)\n\n# t-tests\nfrom scipy.stats import ttest_ind\n\n# 1:1 vs 2:1\np12 = ttest_ind(df_matched[df_matched[\"ratio\"] == 1][\"gave\"],\n                df_matched[df_matched[\"ratio\"] == 2][\"gave\"],\n                equal_var=False)\n\n# 2:1 vs 3:1\np23 = ttest_ind(df_matched[df_matched[\"ratio\"] == 2][\"gave\"],\n                df_matched[df_matched[\"ratio\"] == 3][\"gave\"],\n                equal_var=False)\n\nprint(f\"1:1 vs 2:1 t-test p = {p12.pvalue:.4f}\")\nprint(f\"2:1 vs 3:1 t-test p = {p23.pvalue:.4f}\")\n\nDonation rates by match ratio:\nratio\nControl         NaN\n1          0.020749\n2          0.022633\n3          0.022733\nName: gave, dtype: float64\n1:1 vs 2:1 t-test p = 0.3345\n2:1 vs 3:1 t-test p = 0.9600\n\n\n/tmp/ipykernel_2616514/617877570.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  rates = df_matched.groupby(\"ratio\")[\"gave\"].mean()\n\n\n\n# 创建 dummy 变量\ndf[\"ratio1\"] = (df[\"ratio\"] == 1).astype(int)\ndf[\"ratio2\"] = (df[\"ratio\"] == 2).astype(int)\ndf[\"ratio3\"] = (df[\"ratio\"] == 3).astype(int)\n\n# 只保留 treatment==1 的 matched 组\ndf_matched = df[df[\"treatment\"] == 1]\n\n# 回归\nimport statsmodels.api as sm\n\nX = df_matched[[\"ratio1\", \"ratio2\", \"ratio3\"]]\nX = sm.add_constant(X)\ny = df_matched[\"gave\"]\n\nmodel = sm.OLS(y, X).fit()\nmodel.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nconst\n-1.597075e+09\n3.428594e+11\n-0.004658\n0.996283\n-6.736135e+11\n6.704193e+11\n\n\nratio1\n1.597075e+09\n3.428594e+11\n0.004658\n0.996283\n-6.704193e+11\n6.736135e+11\n\n\nratio2\n1.597075e+09\n3.428594e+11\n0.004658\n0.996283\n-6.704193e+11\n6.736135e+11\n\n\nratio3\n1.597075e+09\n3.428594e+11\n0.004658\n0.996283\n-6.704193e+11\n6.736135e+11\n\n\n\n\n\n\n\n\n# 响应率\nrate_1 = df_matched[df_matched[\"ratio\"] == 1][\"gave\"].mean()\nrate_2 = df_matched[df_matched[\"ratio\"] == 2][\"gave\"].mean()\nrate_3 = df_matched[df_matched[\"ratio\"] == 3][\"gave\"].mean()\n\nprint(f\"1:1 vs 2:1 difference: {rate_2 - rate_1:.4f}\")\nprint(f\"2:1 vs 3:1 difference: {rate_3 - rate_2:.4f}\")\n\n1:1 vs 2:1 difference: 0.0019\n2:1 vs 3:1 difference: 0.0001\n\n\n\nimport statsmodels.api as sm\n\nX = df[\"treatment\"]\nX = sm.add_constant(X)\ny = df[\"amount\"]\n\nmodel = sm.OLS(y, X).fit()\nmodel.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nconst\n0.813268\n0.067418\n12.062995\n1.843438e-33\n0.681127\n0.945409\n\n\ntreatment\n0.153605\n0.082561\n1.860503\n6.282029e-02\n-0.008216\n0.315426\n\n\n\n\n\n\n\n\ndf_gave = df[df[\"gave\"] == 1]\n\nX = df_gave[\"treatment\"]\nX = sm.add_constant(X)\ny = df_gave[\"amount\"]\n\nmodel_gave = sm.OLS(y, X).fit()\nmodel_gave.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nconst\n45.540268\n2.423378\n18.792063\n5.473578e-68\n40.784958\n50.295579\n\n\ntreatment\n-1.668393\n2.872384\n-0.580839\n5.614756e-01\n-7.304773\n3.967986\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Prepare data\ncontrol_amounts = df[(df[\"treatment\"] == 0) & (df[\"gave\"] == 1)][\"amount\"]\ntreatment_amounts = df[(df[\"treatment\"] == 1) & (df[\"gave\"] == 1)][\"amount\"]\n\n# Plot for control group\nfig, ax = plt.subplots()\nax.hist(control_amounts, bins=30, alpha=0.7, label=\"Control\", color=\"skyblue\")\nax.axvline(control_amounts.mean(), color=\"red\", linestyle=\"--\", label=\"Control Mean\")\nax.set_title(\"Donation Amounts: Control Group\")\nax.set_xlabel(\"Amount\")\nax.set_ylabel(\"Frequency\")\nax.legend()\nfig\n\n# Plot for treatment group\nfig, ax = plt.subplots()\nax.hist(treatment_amounts, bins=30, alpha=0.7, label=\"Treatment\", color=\"lightgreen\")\nax.axvline(treatment_amounts.mean(), color=\"red\", linestyle=\"--\", label=\"Treatment Mean\")\nax.set_title(\"Donation Amounts: Treatment Group\")\nax.set_xlabel(\"Amount\")\nax.set_ylabel(\"Frequency\")\nax.legend()\nfig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set probabilities\np_control = 0.018\np_treatment = 0.022\nn = 10_000\n\n# Simulate donation outcomes\nnp.random.seed(42)\ncontrol = np.random.binomial(n=1, p=p_control, size=n)\ntreatment = np.random.binomial(n=1, p=p_treatment, size=n)\n\n# Calculate difference vector and cumulative average\ndiff = treatment - control\ncumulative_avg = np.cumsum(diff) / np.arange(1, n + 1)\n\n# Plot cumulative average\nfig, ax = plt.subplots()\nax.plot(cumulative_avg, label=\"Cumulative Average\")\nax.axhline(y=0.004, color=\"red\", linestyle=\"--\", label=\"True Treatment Effect (0.004)\")\nax.set_title(\"Law of Large Numbers: Cumulative Average of Differences\")\nax.set_xlabel(\"Sample Size\")\nax.set_ylabel(\"Cumulative Average\")\nax.legend()\nfig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set random seed\nnp.random.seed(123)\n\n# Simulation parameters\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\n\n# Create 4 histograms\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\n\nfor i, n in enumerate(sample_sizes):\n    differences = []\n    for _ in range(1000):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        diff = treatment.mean() - control.mean()\n        differences.append(diff)\n\n    ax = axs[i // 2, i % 2]\n    ax.hist(differences, bins=30, color=\"grey\", edgecolor=\"black\")\n    ax.set_title(f\"Sample Size: {n}\")\n    ax.set_xlabel(\"Average Difference\")\n    ax.set_ylabel(\"Frequency\")\n\nplt.tight_layout()\nfig"
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. For at least one variable, perform the test as both t-test (use the formula in the class slides) and separately as a linear regression (regress for example mrm2 on treatment); confirm both methods yield the exact same results. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made (you can do this as a bivariate linear regression if you want). It may help to confirm your calculations match Table 2a Panel A. Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or something that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control.\nNOTE: Linear regression results appear replicate Table 3 column 1 in the paper. Probit results do not, despite Table 3 indicating its results come from probit regressions…\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plots: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. This average will likely be “noisey” when only averaging a few numbers, but should “settle down” and approximate the treatment effect (0.004 = 0.022 - 0.018) as the sample size gets large. Explain the chart to the reader.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms at sample sizes 50, 200, 500, and 1000. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. The repeat for the other 3 histograms. Explain this sequence of histograms and its relationship to the central limit theorem to the reader."
  },
  {
    "objectID": "project/hw1/index.html#charitable-contribution-made-1",
    "href": "project/hw1/index.html#charitable-contribution-made-1",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Charitable Contribution Made",
    "text": "Charitable Contribution Made\nWe begin by comparing donation rates between the treatment and control groups. In the graph below, we see the proportion of individuals who gave any donation, split by whether they received a matching offer or not.\n\nimport statsmodels.formula.api as smf\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n# 创建 treatment vs control 捐款比例 barplot 所需数据\ngave_by_group = df.groupby(\"treatment\")[\"gave\"].mean().rename({0: \"Control\", 1: \"Treatment\"})\n\n# t-test 检验：是否捐款 (gave) 在 treatment vs control 中有显著差异\nt_stat, p_value = stats.ttest_ind(\n    df[df[\"treatment\"] == 1][\"gave\"],\n    df[df[\"treatment\"] == 0][\"gave\"],\n    equal_var=False\n)\n\n# 线性回归：gave ~ treatment\nols_model = smf.ols(\"gave ~ treatment\", data=df).fit()\n\n# Probit 回归\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit(disp=False)\n\n# 绘图\nfig, ax = plt.subplots(figsize=(6,4))\ngave_by_group.plot(kind='bar', color=[\"pink\", \"blue\"], ax=ax)\nax.set_ylabel(\"Proportion Donated\")\nax.set_title(\"Donation Rate by Treatment Group\")\nax.set_xticklabels([\"Control\", \"Treatment\"], rotation=0)\nax.set_ylim(0, 0.05)\nplt.tight_layout()\n\n\nprint(\"t =\", t_stat, \"p =\", p_value)\n\nprint(ols_model.summary2().tables[1])\n\nprint(probit_model.summary2().tables[1])\n\nt = 3.2094621908279835 p = 0.001330982345091417\n              Coef.  Std.Err.          t         P&gt;|t|    [0.025    0.975]\nIntercept  0.017858  0.001101  16.224643  4.779032e-59  0.015701  0.020016\ntreatment  0.004180  0.001348   3.101361  1.927403e-03  0.001538  0.006822\n              Coef.  Std.Err.         z     P&gt;|z|    [0.025    0.975]\nIntercept -2.100141  0.023316 -90.07277  0.000000 -2.145840 -2.054443\ntreatment  0.086785  0.027879   3.11293  0.001852  0.032143  0.141426\n\n\n\n\n\n\n\n\n\nThe donation rate for the control group is approximately 1.8%, while for the treatment group it is 2.2%. This difference is statistically significant:\nA t-test yields t = 3.21, p = 0.0013, indicating that the observed difference is unlikely to be due to random chance.\nA linear probability model (OLS) confirms this result with a positive and significant coefficient on treatment:\n\nols_model.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n0.017858\n0.001101\n16.224643\n4.779032e-59\n0.015701\n0.020016\n\n\ntreatment\n0.004180\n0.001348\n3.101361\n1.927403e-03\n0.001538\n0.006822\n\n\n\n\n\n\n\nTo further validate the result, we estimate a probit model of donation on treatment status. The probit coefficient is 0.087 (p = 0.0019), again confirming a statistically significant effect of matching offers.\n\nprobit_model.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\n\n\nIntercept\n-2.100141\n0.023316\n-90.07277\n0.000000\n-2.145840\n-2.054443\n\n\ntreatment\n0.086785\n0.027879\n3.11293\n0.001852\n0.032143\n0.141426\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThese results suggest that offering a matching donation significantly increases the likelihood that a person will donate. From a behavioral standpoint, this provides evidence that people are more motivated to give when they feel their contribution will be amplified.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nT-test Comparisons To examine whether the size of the match ratio affects donation behavior, I restrict the sample to the treatment group and compute the donation rate for each ratio subgroup:\n1:1 match ratio → 2.07%\n2:1 match ratio → 2.02%\n3:1 match ratio → 2.27%\nI then perform t-tests to compare the donation rates between different match sizes:\n1:1 vs 2:1: p = 0.3345\n2:1 vs 3:1: p = 0.9600\nThese p-values indicate that the differences in response rates across match ratios are not statistically significant. Therefore, larger match ratios do not appear to generate significantly higher giving rates, consistent with what Karlan & List describe on page 8: “the figures suggest no consistent pattern.”\nRegression Analysis To validate this further, I estimate a linear regression model with dummy variables indicating the different match ratios:\n\ndf[\"ratio1\"] = (df[\"ratio\"] == 1).astype(int)\ndf[\"ratio2\"] = (df[\"ratio\"] == 2).astype(int)\ndf[\"ratio3\"] = (df[\"ratio\"] == 3).astype(int)\n\nThe regression on gave using these dummies among the treatment group yields:\nAll coefficients are not statistically significant (p &gt; 0.99)\nCoefficients are extremely small, confirming the weak impact of match ratio levels on response behavior\nDirect Comparison of Response Rates Finally, I directly compute the differences in average donation rates:\n2:1 – 1:1 difference = 0.0019\n3:1 – 2:1 difference = 0.0001\nAgain, the numerical differences are very small, further supporting the conclusion that increasing the match ratio from 1:1 to 3:1 does not lead to materially greater giving.\n\n\n\n\n\n\nConclusion\n\n\n\nTaken together, these results replicate the original findings: while matched donations do increase overall giving compared to no match, increasing the generosity of the match offer (from 1:1 to 3:1) does not significantly boost response rates.\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nFull Sample We begin by regressing the donation amount on the treatment status across the full sample. The estimated coefficient on the treatment dummy is 0.154, but the p-value is approximately 0.063, which suggests the result is not statistically significant at the 5% level. This implies that when considering all individuals, offering a matching grant may increase donation amounts, but the evidence is not conclusive.\nConditional on Donating Next, we restrict the sample to only those who made a donation. This allows us to analyze how much respondents donate conditional on giving something. The treatment coefficient becomes -1.669, with a p-value of 0.561, indicating no statistically significant difference in the donation size between treatment and control groups among those who chose to give.\nThis suggests that while the offer of a match may increase the likelihood of donating (as shown earlier), it does not significantly impact the amount donated by those who do choose to donate.\nDistributional Plots We also visualize the distribution of donation amounts for treatment and control groups using histograms:\n\n# Paste your existing plotting code here.\nimport matplotlib.pyplot as plt\n\n# Prepare data\ncontrol_amounts = df[(df[\"treatment\"] == 0) & (df[\"gave\"] == 1)][\"amount\"]\ntreatment_amounts = df[(df[\"treatment\"] == 1) & (df[\"gave\"] == 1)][\"amount\"]\n\n# Plot for control group\nfig, ax = plt.subplots()\nax.hist(control_amounts, bins=30, alpha=0.7, label=\"Control\", color=\"skyblue\")\nax.axvline(control_amounts.mean(), color=\"red\", linestyle=\"--\", label=\"Control Mean\")\nax.set_title(\"Donation Amounts: Control Group\")\nax.set_xlabel(\"Amount\")\nax.set_ylabel(\"Frequency\")\nax.legend()\nfig\n\n# Plot for treatment group\nfig, ax = plt.subplots()\nax.hist(treatment_amounts, bins=30, alpha=0.7, label=\"Treatment\", color=\"lightgreen\")\nax.axvline(treatment_amounts.mean(), color=\"red\", linestyle=\"--\", label=\"Treatment Mean\")\nax.set_title(\"Donation Amounts: Treatment Group\")\nax.set_xlabel(\"Amount\")\nax.set_ylabel(\"Frequency\")\nax.legend()\nfig"
  }
]